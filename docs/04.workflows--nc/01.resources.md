---
permalink: /resources/
---

# Resources

An important requirement for HPC scheduling is an adequate assertion of a job's required resources. In kubernetes, a job can request CPU and memory resources.
Both requests can also set a limit which may not be surpassed by the job. For more information, see kubernetes' [documentation][1].

## Units

CPU

| Value  | Meaning              |
| ------ | -------------------- |
| `1.0`  | 1 core               |
| `100m` | 100 milli = 0.1 core |

Memory

| Value   | Meaning                             |
| ------- | ----------------------------------- |
| `100Mi` | 100 mebibytes = 100 \* 1024^2 bytes |
| `100M`  | 100 megabytes = 100e6 bytes         |
| `2Gi`   | 2 gibibytes = 2 \* 1024^3 bytes     |
| `2G`    | 2 gigabytes = 2e9 bytes             |

## In Bio-Node

Every node in Bio-Node is scheduled as a job on the kubernetes cluster. Moreover, a node running in parallel creates one sub-job per run. Therefore, resource allocation is critically important for a workflow's performance.
The resource requirements are configured in a node's settings, which are pre-populated by the node's image meta labels. If no requirements are specified, the default is 100Mi\[Bytes\] for memory and 100m\[cores\] for CPU.

In addition to resource requests, limits are also added to the jobs. Limits cannot be overridden manually, they are always set to 2$\times$ the job's requests. A job requesting 200Mi memory and 150m CPU will thus be throttled when
exceeding 300m CPU and killed when exceeding 400Mi memory.

## Auto resources

If you're creating a new workflow with unknown resource requirements, you probably need to spend some time figuring out the exact requests. The default values are really small, and every job taking ≥200Mi Bytes memory
will be **killed** if no specific resources are set.
When this happens, you need to find out which values to request. A good approach is the following:

1. Select a small subset of inputs for your workflow, i.e. just 10 samples of 1000
1. Estimate the resources of every node in your workflow, overestimating slightly
    1. If you cannot make a guess, use the size of a cluster node, i.e. 16.0 cores and 30.0 Gi.
1. Run the workflow with the small sample. The workflow should not crash anymore.
1. Press the button _Update Resource Quotas_
1. Create a template of your workflow to examine the resulting resources.

This will have set the resource requests as the maximum value encountered during runtime of the workflow.

::: warning
Jobs that finish in a very short time (≈3min) cannot be measured for resource limits. You have to set manual resource requests for those.
:::

[1]: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#resource-requests-and-limits-of-pod-and-container
